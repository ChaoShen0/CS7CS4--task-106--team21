{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_vis(imgs):\n",
    "    \"\"\"takes a list of images and show them side-by-side in a grid\"\"\"\n",
    "    nh = nw = int(np.ceil(np.sqrt(len(imgs))))\n",
    "    h, w = imgs[0].shape\n",
    "    grid = np.zeros((nh*h, nw*w))\n",
    "    for n, img in enumerate(imgs):\n",
    "        i, j = n%nh, n//nh\n",
    "        grid[j*h:(j+1)*h, i*w:(i+1)*w] = img\n",
    "    return grid\n",
    "\n",
    "def preprocess(x):\n",
    "    \"\"\"\n",
    "    reshape vectors back to images\n",
    "    pad with 2 zero pixel border to make shapes nice\n",
    "    rescale values to 0 mean -1 to 1 range (from usual 0 to 1)\n",
    "    \"\"\"\n",
    "    x = x.reshape(-1, 28, 28)\n",
    "    x = np.pad(x, [[0, 0], [2, 2], [2, 2]], mode='constant', constant_values=0)\n",
    "    return x[:, :, :, np.newaxis]*2-1\n",
    "\n",
    "def dense(x, scope, n_h):\n",
    "    \"\"\"\n",
    "    standard affine layer\n",
    "    scope = name tf variable scope\n",
    "    n_h   = number of hidden units\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope):\n",
    "        n_x = x.get_shape().as_list()[-1]\n",
    "        w = tf.get_variable('w', [n_x, n_h], initializer=tf.random_normal_initializer(stddev=0.04))\n",
    "        b = tf.get_variable('b', [n_h], initializer=tf.constant_initializer(0))\n",
    "        return tf.matmul(x, w)+b\n",
    "    \n",
    "def conv(x, scope, r_f, n_f, stride=1):\n",
    "    \"\"\"\n",
    "    standard conv layer\n",
    "    scope  = name tf variable scope\n",
    "    r_f    = receptive field of kernel\n",
    "    n_f    = # of kernels\n",
    "    stride = locations\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope):\n",
    "        n_x = x.get_shape().as_list()[-1]\n",
    "        w = tf.get_variable('w', [r_f, r_f, n_x, n_f], initializer=tf.random_normal_initializer(stddev=0.04))\n",
    "        b = tf.get_variable('b', [n_f], initializer=tf.constant_initializer(0))\n",
    "        return tf.nn.convolution(x, w, padding='SAME', strides=[stride, stride])+b\n",
    "\n",
    "def upsample(x, ratio=2):\n",
    "    \"\"\"\n",
    "    takes a 4D image tensor and increases spatial resolution by replicating values\n",
    "    so for ratio=2 a 2x2 image becomes a 4x4 image with each value repeated twice\n",
    "    ratio = # of spatial repeats\n",
    "    \"\"\"\n",
    "    n_h, n_w = x.get_shape().as_list()[1:3]\n",
    "    return tf.image.resize_nearest_neighbor(x, [n_h*ratio, n_w*ratio])\n",
    "    \n",
    "def generator(Z, reuse=False):\n",
    "    \"\"\"\n",
    "    modified DCGAN (progressive GAN-ized)\n",
    "    consists of interleaved upsample and convolution operations\n",
    "    leaky relu used for good gradient flow\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        h = tf.nn.leaky_relu(dense(Z, 'hz', n_h=256*4*4), 0.2)\n",
    "        h = tf.reshape(h, [n_batch, 4, 4, 256]) #convert from feature vector to 4D image tensor\n",
    "        h = upsample(h)\n",
    "        h = tf.nn.leaky_relu(conv(h, 'h', r_f=5, n_f=128), 0.2)\n",
    "        h = upsample(h)\n",
    "        h = tf.nn.leaky_relu(conv(h, 'h2', r_f=5, n_f=64), 0.2)\n",
    "        h = upsample(h)\n",
    "        h = tf.nn.leaky_relu(conv(h, 'h3', r_f=5, n_f=32), 0.2)\n",
    "        x = conv(h, 'hx', r_f=1, n_f=n_c) #linear output - could use sigmoid or tanh but gradient vanishing issues\n",
    "        return x\n",
    "    \n",
    "def discriminator(X, reuse=False):\n",
    "    \"\"\"\n",
    "    DCGAN disriminator without batchnorm for simplicity\n",
    "    leaky relu used for good gradient flow + smoother function\n",
    "    keep model shallow and simple with quick downsample via strided convolutions\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        h = tf.nn.leaky_relu(conv(X, 'hx', r_f=5, n_f=32, stride=2), 0.2)\n",
    "        h = tf.nn.leaky_relu(conv(h, 'h', r_f=5, n_f=64, stride=2), 0.2)\n",
    "        h = tf.nn.leaky_relu(conv(h, 'h2', r_f=5, n_f=128, stride=2), 0.2)\n",
    "        h = tf.reshape(h, [n_batch, -1]) #convert from 4D image tensor to feature vector\n",
    "        logits = dense(h, 'clf', 1)\n",
    "        return logits\n",
    "    \n",
    "def cross_entropy_loss(logits, labels):\n",
    "    \"\"\"\n",
    "    default GAN training loss\n",
    "    \"\"\"\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "\n",
    "def noise(n, n_z):\n",
    "    \"\"\"\n",
    "    n random spherical gaussian noise with unit variance\n",
    "    \"\"\"\n",
    "    return np.random.randn(n, n_z).astype(np.float32)\n",
    "\n",
    "def visualize(z):\n",
    "    \"\"\"\n",
    "    show evolution of samples of the same points in latent space over training\n",
    "    \"\"\"\n",
    "    g_z_sample = sess.run(g_z, {Z:z})\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    plt.title('G: %.3f D: %.3f Updates: %d'%(g_cost, d_cost, n_updates))\n",
    "    plt.imshow(grid_vis(np.clip((g_z_sample.reshape(-1, 32, 32)+1)/2, 0, 1)), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#setup and hyperparameters\n",
    "mnist = input_data.read_data_sets('data/')\n",
    "n_h, n_w, n_c = [32, 32, 1]\n",
    "n_z = 128\n",
    "n_batch = 100\n",
    "lr = 2.5e-4\n",
    "n_updates_total = 55000\n",
    "z_vis = noise(n_batch, n_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tensorflow inputs\n",
    "X = tf.placeholder(tf.float32, [None, n_h, n_w, n_c])\n",
    "Z = tf.placeholder(tf.float32, [None, n_z])\n",
    "\n",
    "#setup modules\n",
    "g_z   = generator(Z)\n",
    "d_g_z = discriminator(g_z)\n",
    "d_x   = discriminator(X, reuse=True)\n",
    "\n",
    "#generator tries to get discriminator to classify its samples as real\n",
    "g_loss     = cross_entropy_loss(logits=d_g_z, labels=tf.ones(tf.shape(d_g_z)))\n",
    "#discriminator tries to classify generator samples as fake\n",
    "d_g_z_loss = cross_entropy_loss(logits=d_g_z, labels=tf.zeros(tf.shape(d_g_z)))\n",
    "#discriminator tries to classify data samples as real\n",
    "d_x_loss   = cross_entropy_loss(logits=d_x,   labels=tf.ones(tf.shape(d_x)))\n",
    "#overall discriminator objective is correctly classifying both real and fake data\n",
    "d_loss     = (d_g_z_loss + d_x_loss)/2\n",
    "\n",
    "#build training ops\n",
    "g_vars  = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='generator')\n",
    "g_train = tf.train.AdamOptimizer(learning_rate=lr, beta1=0.5).minimize(g_loss,  var_list=g_vars)\n",
    "d_vars  = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='discriminator')\n",
    "d_train = tf.train.AdamOptimizer(learning_rate=lr, beta1=0.5).minimize(d_loss,  var_list=d_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#alternate updates of discriminator on minibatches of real data and generator\n",
    "%matplotlib inline\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for n_updates in tqdm(list(range(n_updates_total)), ncols=80, leave=False):\n",
    "    xs, _ = mnist.train.next_batch(n_batch)\n",
    "    d_cost, _ = sess.run([d_loss, d_train], {X:preprocess(xs), Z:noise(n_batch, n_z)})\n",
    "    g_cost, _ = sess.run([g_loss, g_train], {Z:noise(n_batch, n_z)})\n",
    "    if n_updates % 100 == 0:\n",
    "        visualize(z_vis)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:openai]",
   "language": "python",
   "name": "conda-env-openai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
